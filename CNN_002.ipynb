{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTBN59gUR6yFm5RewSimfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayIvTkachenko/Colab_Python_AI_NeuroNetwork/blob/main/CNN_002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hqku8Rp_wrxo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ds = tf.data.Dataset.list_files(\"/path/to/csv/files/1.csv\")\n"
      ],
      "metadata": {
        "id": "__x3xI1y0ofp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "ZyZoGMy0_tOC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = \"./input_data/images/\"\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    directory = image_directory,\n",
        "    label_mode = \"int\",\n",
        "    validation_split = 0.3,\n",
        "    subset = \"training\",\n",
        "    image_size = (28, 28),\n",
        "    batch_size = 64\n",
        ")\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    directory = image_directory,\n",
        "    label_mode = \"int\",\n",
        "    validation_split = 0.3,\n",
        "    subset = \"validation\",\n",
        "    image_size = (28, 28),\n",
        "    batch_size = 64\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "VDs1XkAiADlX",
        "outputId": "44153105-eee4-4903-b006-83fb45e49db7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "If using `validation_split` and shuffling the data, you must provide a `seed` argument, to make sure that there is no overlap between the training and validation subset.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2786073457.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./input_data/images/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_dataset = image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    224\u001b[0m         )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     dataset_utils.check_validation_split_arg(\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mcheck_validation_split_arg\u001b[0;34m(validation_split, subset, shuffle, seed)\u001b[0m\n\u001b[1;32m    757\u001b[0m         )\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    760\u001b[0m             \u001b[0;34m\"If using `validation_split` and shuffling the data, you must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;34m\"provide a `seed` argument, to make sure that there is no \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: If using `validation_split` and shuffling the data, you must provide a `seed` argument, to make sure that there is no overlap between the training and validation subset."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"COLAB_TPU_ADDR\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "IAF6wLdgD_ip",
        "outputId": "9f561c60-7526-4a16-eec9-2bc41f1c177b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'COLAB_TPU_ADDR'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1215583061.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"COLAB_TPU_ADDR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input((28, 28, 1))\n",
        "conv_1 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same')(inputs)\n",
        "act_1 = tf.keras.layers.Activation(\"relu\")(conv_1)\n",
        "pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides==(1, 1), padding='valid',)(act_1)\n",
        "do_1 = tf.keras.layers.Dropout|(0.6)(pool_1)\n",
        "conv_2 = tf.keras.layers.Conv2D(16, (3, 3), padding='same')(do_1)\n",
        "act_2 = tf.keras.layers.Activation(\"relu\")(conv_2)\n",
        "pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (act_2)\n",
        "do_2 = tf.keras.layers.Dropout(0.6)(pool_2)\n",
        "conv_3 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(do_2)\n",
        "act_3 = tf.keras.layers.Activation(\"relu\")(conv_3)\n",
        "pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(act_3)\n",
        "do_3 = tf.keras.layers.Dropout(0.6)(pool_3)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(do_3)\n",
        "\n",
        "dense_1 = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=\"L1L2\")(flatten)\n",
        "dense_2 = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=\"L1L2\")(dense_1)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(dense_2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ex2j9mLZEINM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDI3ekGlI3Q3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}